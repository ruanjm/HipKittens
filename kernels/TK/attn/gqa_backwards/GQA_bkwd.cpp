#include "kittens.cuh"
#include "pyutils/pyutils.cuh"

constexpr int ATTN_B = 16; // batch size
constexpr int ATTN_H = 16; // number of heads
constexpr int ATTN_N = 2048; // sequence length
constexpr int ATTN_D = 128; // dimension
constexpr int BLOCK_SIZE = 32; // block size

#define NUM_WARPS 1
#define NUM_THREADS (kittens::WARP_THREADS * NUM_WARPS)

using namespace kittens;

template<int D, typename T=bf16, typename L=row_l> using qkvo_tile = rt<T, BLOCK_SIZE, D, L>;
template<int D, typename T=float, typename L=row_l> using attn_tile = rt<T, BLOCK_SIZE, BLOCK_SIZE, L>;

template<int D> struct attn_globals { 
    gl<bf16, -1, -1, -1, -1> Qg, Kg, Vg, Og, dOg, dQg;
    gl<bf16, -1, -1, -1, 1> m_vec, l_vec;
    dim3 grid() { return dim3(ATTN_B, ATTN_H, ATTN_N / BLOCK_SIZE); }
    dim3 block() { return dim3(NUM_THREADS); }
    size_t dynamic_shared_memory() { return 16384; }
};

template<int D> __launch_bounds__(NUM_THREADS, 1)
__global__ void attend_bwd_dq_ker(const attn_globals<D> g) {
    
    const int b = blockIdx.x;
    const int h = blockIdx.y;
    const int i = blockIdx.z;

    const float scale_factor = 1.0f / sqrt(D);

    // tiles
    qkvo_tile<D, bf16, row_l> q_reg, k_reg, v_reg;
    qkvo_tile<D, bf16, col_l> k_reg_col;
    qkvo_tile<D, bf16, row_l> dO_reg, O_reg;
    qkvo_tile<D, float, accum_col_l> dQ_acc; 
    zero(dQ_acc);

    // load Q_i, dO_i, O_i, and stats (m,l)
    load(q_reg,  g.Qg,  {b,h,i,0});
    load(dO_reg, g.dOg, {b,h,i,0});
    load(O_reg,  g.Og,  {b,h,i,0});
    typename attn_tile<D,float,col_l>::col_vec m_vec, l_vec;
    load(m_vec, g.m_vec, {b,h,i,0});
    load(l_vec, g.l_vec, {b,h,i,0});

    // Δ_i = row_sum(dO ⊙ O) - FIX: use float for computation
    qkvo_tile<D, float, row_l> tmp_float;
    qkvo_tile<D, float, row_l> dO_float, O_float;
    
    // Convert to float for computation
    copy(dO_float, dO_reg);
    copy(O_float, O_reg);
    
    mul(tmp_float, dO_float, O_float);
    col_vec<attn_tile<D,float,row_l>> delta_vec;
    row_sum(delta_vec, tmp_float);  // Now both are float

    int num_blocks = ATTN_N/BLOCK_SIZE;
    for (int j = 0; j < num_blocks; ++j) {
        load(k_reg, g.Kg, {b,h,j,0});
        load(v_reg, g.Vg, {b,h,j,0});

        // Convert k_reg to col layout
        swap_layout(k_reg_col, k_reg);

        // S_ij = (Q_i K_j^T)*scale
        attn_tile<D,float,accum_col_l> S; zero(S);
        mma_ABt(S, q_reg, k_reg, S);
        mul(S, S, scale_factor);

        // P_ij = exp(S - m)/l
        sub_row(S, S, m_vec);
        exp(S, S);
        div_row(S, S, l_vec);
        attn_tile<D,float,accum_col_l> P; 
        copy(P, S);

        // dOVt = dO_i V_j^T
        attn_tile<D,float,accum_col_l> dOVt; 
        zero(dOVt);
        mma_ABt(dOVt, dO_reg, v_reg, dOVt);

        // dS = P ⊙ (dOVt - Delta)
        sub_col(dOVt, dOVt, delta_vec);
        mul(dOVt, dOVt, P);

        // dQ += dS K_j * scale
        qkvo_tile<D,float,accum_col_l> dQ_blk; 
        zero(dQ_blk);
        
        // Convert dOVt to row layout
        attn_tile<D,float,row_l> dOVt_row;
        swap_layout(dOVt_row, dOVt);
        
        // Convert to bf16 for MMA operation
        attn_tile<D,bf16,row_l> dOVt_bf16_row;
        copy(dOVt_bf16_row, dOVt_row);
        
        mma_AB(dQ_blk, dOVt_bf16_row, k_reg_col, dQ_blk);
        mul(dQ_blk, dQ_blk, scale_factor);
        add(dQ_acc, dQ_acc, dQ_blk);
    }

    // store dQ (bf16)
    qkvo_tile<D,bf16,accum_col_l> dQ_reg; 
    copy(dQ_reg, dQ_acc);
    store(g.dQg, dQ_reg, {b,h,i,0});
}

template<int D>
void dispatch_micro(attn_globals<D> g) {
    unsigned long mem_size = g.dynamic_shared_memory();
    hipFuncSetAttribute((void*)attend_bwd_dq_ker<D>, hipFuncAttributeMaxDynamicSharedMemorySize, mem_size);
    attend_bwd_dq_ker<D><<<g.grid(), g.block(), mem_size>>>(g);
    hipDeviceSynchronize();
}

PYBIND11_MODULE(tk_kernel, m) {
    m.doc() = "tk_kernel python module";
    py::bind_function<dispatch_micro<ATTN_D>>(m, "dispatch_micro", 
        &attn_globals<ATTN_D>::Qg, 
        &attn_globals<ATTN_D>::Kg, 
        &attn_globals<ATTN_D>::Vg, 
        &attn_globals<ATTN_D>::Og, 
        &attn_globals<ATTN_D>::dOg, 
        &attn_globals<ATTN_D>::dQg,
        &attn_globals<ATTN_D>::m_vec, 
        &attn_globals<ATTN_D>::l_vec
    );
}
